---
title: 'Assessing the Impact of Automated Suggestions on Decision Making: Domain Experts Mediate Model Errors but Take Less Initiative'
authors:
  - name: Ariel Levy
    affiliation: MIT CSAIL
  - name: Monica Agrawal
    affiliation: MIT CSAIL
  - key: arvindsatya
  - name: David Sontag
    affiliation: MIT CSAIL
venue: chi
year: 2021
doi: 10.1145/3411764.3445522
tags:
  - human-ai interaction
  - empirical study
  - quantitative methods
teaser: Accuracy (total recall) and efficiency (time to label) results for users with label recommendations (Standard and Weakened modes) and users without (None mode).
videos:
  - name: CHI 2021 Talk
    key: iqahsetvD58
---
Automated decision support can accelerate tedious tasks as users can focus their attention where it is needed most. However, a key concern is whether users overly trust or cede agency to automation. In this paper, we investigate the effects of introducing automation to annotating clinical texts â€” a multi-step, error-prone task of identifying clinical concepts (e.g., procedures) in medical notes, and mapping them to labels in a large ontology. We consider two forms of decision aid: recommending which labels to map concepts to, and pre-populating annotation suggestions. Through laboratory studies, we find that 18 clinicians generally build intuition of when to rely on automation and when to exercise their own judgement. However, when presented with fully pre-populated suggestions, these expert users exhibit less agency: accepting improper mentions, and taking less initiative in creating additional annotations. Our findings inform how systems and algorithms should be designed to mitigate the observed issues.
